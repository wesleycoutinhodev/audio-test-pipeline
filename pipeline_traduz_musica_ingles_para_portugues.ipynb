{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wesleycoutinhodev/audio-test-pipeline/blob/main/pipeline_traduz_musica_ingles_para_portugues.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline de Tradução de Música com Whisper\n",
        "\n",
        "Instruções para criar um pipeline completo de tradução de música do inglês para o português usando a biblioteca Whisper.\n",
        "\n",
        "## instrucao1 - Instalação da biblioteca Whisper\n",
        "\n",
        "```bash\n",
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "```\n",
        "\n",
        "## instrucao2 - Instalação do programa ffmpeg\n",
        "\n",
        "```bash\n",
        "!apt-get install -y ffmpeg\n",
        "```\n",
        "\n",
        "## instrucao3 - Download do arquivo .mp4\n",
        "\n",
        "```bash\n",
        "!wget https://github.com/wesleycoutinhodev/audio-test-pipeline/raw/refs/heads/main/Pearl%20Jam%20-%20Black%20(Official%20Audio).mp3```\n",
        "\n",
        "## instrucao4 - Transcrição do áudio\n",
        "\n",
        "```python\n",
        "import whisper\n",
        "\n",
        "audio_path = \"/content/Adrienne.mp4\"\n",
        "\n",
        "print(f\"Arquivo: {audio_path}\")\n",
        "\n",
        "# Modelos possíveis: tiny, base, small, medium, large\n",
        "# \"small\" é rápido e bom para português, \"large\" é mais preciso mas mais lento\n",
        "modelo_selecionado = \"small\"\n",
        "print(f\"Carregando o modelo: {modelo_selecionado}\")\n",
        "model = whisper.load_model(modelo_selecionado)\n",
        "print(\"Modelo carregado com sucesso!\")\n",
        "\n",
        "try:\n",
        "  print(f\"Iniciando a transcrição do áudio {audio_path}\")\n",
        "  # Transcrever\n",
        "  result = model.transcribe(audio_path, language=\"pt\")\n",
        "  print(\"\\n--- TRANSCRIÇÃO COMPLETA ---\\n\")\n",
        "  print(result[\"text\"])\n",
        "\n",
        "  print(f\"Salvando o texto...\")\n",
        "  # Salvar transcrição em arquivo TXT\n",
        "  nome_arquivo_texto = \"transcricao.txt\"\n",
        "  with open(nome_arquivo_texto, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(result[\"text\"])\n",
        "  print(\"Texto salvo com sucesso!\")\n",
        "except Exception as ex:\n",
        "  print(f\"Erro {str(ex)} ao fazer a transcrição do arquivo {audio_path}\")\n",
        "```\n",
        "\n",
        "## instrucao5 - Engenharia do Prompt de tradução\n",
        "\n",
        "```python\n",
        "# Carregar a transcrição\n",
        "with open(\"transcricao.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    texto_original = f.read()\n",
        "\n",
        "# Prompt para tradução poética\n",
        "prompt_traducao = f\"\"\"\n",
        "Você pode traduzir o seguinte texto de inglês para português?\n",
        "Além disso, você pode deixar essa tradução em um formato mais poético/musical\n",
        "(para soar como letra de música em português)?\n",
        "\n",
        "Texto para traduzir:\n",
        "{texto_original}\n",
        "\"\"\"\n",
        "\n",
        "print(\"Prompt de tradução criado com sucesso!\")\n",
        "print(prompt_traducao[:500] + \"...\")  # Mostrar apenas parte do prompt\n",
        "```\n",
        "\n",
        "## instrucao6 - Salvar a tradução em JSON\n",
        "\n",
        "```python\n",
        "import json\n",
        "\n",
        "# Supondo que temos a tradução (aqui seria substituído pela resposta real da API)\n",
        "traducao_pt = {\n",
        "    \"titulo\": \"Adrienne (Tradução Poética)\",\n",
        "    \"letra_original\": texto_original,\n",
        "    \"letra_traduzida\": \"[Aqui viria a tradução poética gerada]\",\n",
        "    \"artista\": \"Artista Original\",\n",
        "    \"tradutor\": \"Whisper + OpenAI\",\n",
        "    \"data_traducao\": \"2023-11-10\"\n",
        "}\n",
        "\n",
        "# Salvar em arquivo JSON\n",
        "with open(\"traducao_musica.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(traducao_pt, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"Tradução salva em traducao_musica.json\")\n",
        "```\n",
        "\n",
        "## instrucao7 - Explicação da tradução\n",
        "\n",
        "```python\n",
        "# Carregar a tradução\n",
        "with open(\"traducao_musica.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    traducao = json.load(f)\n",
        "\n",
        "# Prompt para explicação da tradução\n",
        "prompt_explicacao = f\"\"\"\n",
        "Agora, uma vez o texto traduzido, você pode explicar o significado dessa tradução em português?\n",
        "\n",
        "Texto original:\n",
        "{traducao['letra_original']}\n",
        "\n",
        "Tradução para português:\n",
        "{traducao['letra_traduzida']}\n",
        "\n",
        "Por favor, explique as escolhas de tradução, o significado da música e como a versão poética em português captura a essência da original.\n",
        "\"\"\"\n",
        "\n",
        "print(\"Prompt para explicação da tradução criado com sucesso!\")\n",
        "print(prompt_explicacao[:500] + \"...\")  # Mostrar apenas parte do prompt\n",
        "```\n",
        "\n",
        "## Pipeline Completo\n",
        "\n",
        "Este pipeline completo:\n",
        "1. Instala as dependências necessárias\n",
        "2. Baixa um arquivo de áudio de exemplo\n",
        "3. Transcreve o áudio usando o modelo Whisper\n",
        "4. Prepara um prompt para tradução poética\n",
        "5. Salva a tradução em formato JSON\n",
        "6. Gera uma explicação sobre as escolhas de tradução\n",
        "\n",
        "Nota: Para completar totalmente o pipeline, seria necessário integrar com uma API de IA (como a API da OpenAI) para processar os prompts de tradução e explicação. O código acima prepara todos os elementos, mas a execução completa dependeria dessa integração adicional."
      ],
      "metadata": {
        "id": "Vmv7BxnWtzNG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementação do Pipeline usando a API do Gemini"
      ],
      "metadata": {
        "id": "HKbF3mLZuFAm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03oekpKrnk9P",
        "outputId": "157b8381-8069-453f-e367-8f3e24a97875"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# instrucao1 - Instalar a biblioteca whisper\n",
        "!pip install -q git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# instrucao2 - Instalar o programa ffmpeg\n",
        "!apt-get install -y ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYuRuIHin6Mn",
        "outputId": "63c62679-b2bf-4c09-e549-aadf6722ae90"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# instrucao3 - Baixar um arquivo .mp4 público\n",
        "!wget https://github.com/armandossrecife/teste/raw/refs/heads/main/Adrienne.mp4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcRQMRjjn8YF",
        "outputId": "36a0dac7-2ad3-48ec-889e-b5f350280a30"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-27 13:37:48--  https://github.com/armandossrecife/teste/raw/refs/heads/main/Adrienne.mp4\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/armandossrecife/teste/refs/heads/main/Adrienne.mp4 [following]\n",
            "--2025-08-27 13:37:48--  https://raw.githubusercontent.com/armandossrecife/teste/refs/heads/main/Adrienne.mp4\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14944332 (14M) [application/octet-stream]\n",
            "Saving to: ‘Adrienne.mp4’\n",
            "\n",
            "Adrienne.mp4        100%[===================>]  14.25M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-08-27 13:37:48 (119 MB/s) - ‘Adrienne.mp4’ saved [14944332/14944332]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar a biblioteca do Google Gemini\n",
        "!pip install -q google-generativeai"
      ],
      "metadata": {
        "id": "AgA1HKXnn-NS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import google.generativeai as genai\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Configurar a API do Google Gemini\n",
        "# Você precisa ter uma chave de API válida\n",
        "GEMINI_API_KEY = \"?\"  # Substitua pela sua chave API\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "# Configurar o modelo Gemini\n",
        "modelo_gemini = genai.GenerativeModel('gemini-2.0-flash')"
      ],
      "metadata": {
        "id": "FKA9lqYIoFYy",
        "outputId": "cd1748a1-ab4b-4889-98b5-432b611190e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'whisper'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3712024819.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerativeai\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgenai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'whisper'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# instrucao4 - Transcrição do áudio com Whisper\n",
        "def transcrever_audio(audio_path):\n",
        "    print(f\"Arquivo: {audio_path}\")\n",
        "\n",
        "    # Modelos possíveis: tiny, base, small, medium, large\n",
        "    modelo_selecionado = \"small\"\n",
        "    print(f\"Carregando o modelo: {modelo_selecionado}\")\n",
        "    model = whisper.load_model(modelo_selecionado)\n",
        "    print(\"Modelo carregado com sucesso!\")\n",
        "\n",
        "    try:\n",
        "        print(f\"Iniciando a transcrição do áudio {audio_path}\")\n",
        "        # Transcrever\n",
        "        result = model.transcribe(audio_path, language=\"pt\")\n",
        "        print(\"\\n--- TRANSCRIÇÃO COMPLETA ---\\n\")\n",
        "        print(result[\"text\"])\n",
        "\n",
        "        print(f\"Salvando o texto...\")\n",
        "        # Salvar transcrição em arquivo TXT\n",
        "        nome_arquivo_texto = \"transcricao.txt\"\n",
        "        with open(nome_arquivo_texto, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(result[\"text\"])\n",
        "        print(\"Texto salvo com sucesso!\")\n",
        "\n",
        "        return result[\"text\"]\n",
        "    except Exception as ex:\n",
        "        print(f\"Erro {str(ex)} ao fazer a transcrição do arquivo {audio_path}\")\n",
        "        return None\n",
        "\n",
        "# instrucao5 - Tradução com Gemini\n",
        "def traduzir_texto(texto_ingles):\n",
        "    prompt_traducao = f\"\"\"\n",
        "    Você pode traduzir o seguinte texto de inglês para português?\n",
        "    Além disso, você pode deixar essa tradução em um formato mais poético/musical\n",
        "    (para soar como letra de música em português)?\n",
        "\n",
        "    Texto para traduzir:\n",
        "    {texto_ingles}\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = modelo_gemini.generate_content(prompt_traducao)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao traduzir: {e}\")\n",
        "        return None\n",
        "\n",
        "# instrucao6 - Salvar em JSON\n",
        "def salvar_traducao_json(texto_original, texto_traduzido, nome_arquivo=\"traducao_musica.json\"):\n",
        "    dados_traducao = {\n",
        "        \"original\": texto_original,\n",
        "        \"traducao_poetica\": texto_traduzido,\n",
        "        \"idioma_original\": \"inglês\",\n",
        "        \"idioma_traducao\": \"português\"\n",
        "    }\n",
        "\n",
        "    with open(nome_arquivo, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(dados_traducao, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"Tradução salva em {nome_arquivo}\")\n",
        "\n",
        "# instrucao7 - Explicação da tradução\n",
        "def explicar_traducao(texto_original, texto_traduzido):\n",
        "    prompt_explicacao = f\"\"\"\n",
        "    Agora, uma vez o texto traduzido, você pode explicar o significado dessa tradução em português?\n",
        "\n",
        "    Texto original em inglês:\n",
        "    {texto_original}\n",
        "\n",
        "    Tradução para português:\n",
        "    {texto_traduzido}\n",
        "\n",
        "    Por favor, explique as escolhas de tradução, o significado da música e como a versão poética em português\n",
        "    captura a essência da original. Escreva em português.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = modelo_gemini.generate_content(prompt_explicacao)\n",
        "\n",
        "        # Salvar explicação em arquivo\n",
        "        with open(\"explicacao_traducao.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(response.text)\n",
        "\n",
        "        print(\"Explicação da tradução salva em explicacao_traducao.txt\")\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao gerar explicação: {e}\")\n",
        "        return None\n",
        "\n",
        "# Função principal para executar o pipeline completo\n",
        "def pipeline_traducao_musica(audio_path):\n",
        "    print(\"=== INICIANDO PIPELINE DE TRADUÇÃO DE MÚSICA ===\\n\")\n",
        "\n",
        "    # Passo 1: Transcrever áudio\n",
        "    print(\"1. Transcrevendo áudio...\")\n",
        "    texto_original = transcrever_audio(audio_path)\n",
        "\n",
        "    if texto_original is None:\n",
        "        print(\"Falha na transcrição. Abortando pipeline.\")\n",
        "        return\n",
        "\n",
        "    # Passo 2: Traduzir texto\n",
        "    print(\"\\n2. Traduzindo texto...\")\n",
        "    texto_traduzido = traduzir_texto(texto_original)\n",
        "\n",
        "    if texto_traduzido is None:\n",
        "        print(\"Falha na tradução. Abortando pipeline.\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n--- TRADUÇÃO POÉTICA ---\\n\")\n",
        "    print(texto_traduzido)\n",
        "\n",
        "    # Passo 3: Salvar em JSON\n",
        "    print(\"\\n3. Salvando tradução em JSON...\")\n",
        "    salvar_traducao_json(texto_original, texto_traduzido)\n",
        "\n",
        "    # Passo 4: Explicar tradução\n",
        "    print(\"\\n4. Gerando explicação da tradução...\")\n",
        "    explicacao = explicar_traducao(texto_original, texto_traduzido)\n",
        "\n",
        "    if explicacao:\n",
        "        print(\"\\n--- EXPLICAÇÃO DA TRADUÇÃO ---\\n\")\n",
        "        print(explicacao)\n",
        "\n",
        "    print(\"\\n=== PIPELINE CONCLUÍDO COM SUCESSO ===\")"
      ],
      "metadata": {
        "id": "Ja0FoSc_oPyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_path = \"/content/Adrienne.mp4\"\n",
        "\n",
        "# Verificar se o arquivo de áudio existe\n",
        "if not os.path.exists(audio_path):\n",
        "  print(f\"Arquivo {audio_path} não encontrado. Verifique o caminho.\")\n",
        "else:\n",
        "  pipeline_traducao_musica(audio_path)"
      ],
      "metadata": {
        "id": "V4I7KDoaoSfT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}